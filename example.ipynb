{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crisis_summary.summary import crisis\n",
    "from utils.util import get_eventsMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file auth already exists.\n"
     ]
    }
   ],
   "source": [
    "# !mkdir auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials = {\n",
    "#     \"institution\": \"Georgetown University\", # University, Company or Public Agency Name\n",
    "#     \"contactname\": \"JaeHo Bahng\", # Your Name\n",
    "#     \"email\": \"jaheo127@gmail.com\", # A contact email address\n",
    "#     \"institutiontype\": \"Academic\" # Either 'Research', 'Industry', or 'Public Sector'\n",
    "# }\n",
    "\n",
    "# # Write this to a file so it can be read when needed\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# with open('./auth/crisisfacts.json', 'w') as f:\n",
    "#     json.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load variables from the .env file\n",
    "load_dotenv('.env')\n",
    "api = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['IR_DATASETS_HOME'] = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsMeta = get_eventsMeta(eventNoList='001', days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColBERTRanker model answerdotai/answerai-colbert-small-v1 (this message can be suppressed by setting verbose=0)\n",
      "No device set\n",
      "Using device cuda\n",
      "No dtype set\n",
      "Using dtype torch.float32\n",
      "Loading model answerdotai/answerai-colbert-small-v1, this might take a while...\n",
      "Linear Dim set to: 96 for downcasting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] building docstore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crisisfacts/001/2017-12-07  processing\n",
      "There are multiple query fields available: ('text', 'indicative_terms', 'trecis_category_mapping', 'event_id', 'event_title', 'event_dataset', 'event_description', 'event_trecis_id', 'event_type', 'event_url'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] To download crisisfacts data, you need to provide your institution, contact person, email, and institution type.\n",
      "\n",
      "To avoid this message in the future, you may also set them in a file named ..\\..\\auth\\crisisfacts.json, in the format of {\"institution\": \"\", \"contactname\": \"\", \"email\": \"\", \"institutiontype\": \"\"}.\n",
      "[INFO] [starting] requesting access key\n",
      "[INFO] [finished] requesting access key [1.11s]\n",
      "docs_iter: 7288doc [00:18, 390.16doc/s]\n",
      "[INFO] [finished] docs_iter: [00:18] [7288doc] [390.14doc/s]\n",
      "[INFO] [finished] building docstore [18.68s]\n",
      "crisisfacts/001/2017-12-07 documents: 7288it [00:00, 10230.66it/s]\n",
      "crisisfacts/001/2017-12-07 documents: 7288it [00:01, 3752.58it/s]\n"
     ]
    }
   ],
   "source": [
    "mine = crisis(events = eventsMeta)\n",
    "\n",
    "final_df, time_taken, memory_used = mine.rank_rerank_colbert(model = 'BM25')\n",
    "result_df = mine.group_doc(final_df)\n",
    "a, b, c = mine.gpt_summary(result_df, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crisisfacts/001/2017-12-07  processing\n",
      "There are multiple query fields available: ('text', 'indicative_terms', 'trecis_category_mapping', 'event_id', 'event_title', 'event_dataset', 'event_description', 'event_trecis_id', 'event_type', 'event_url'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crisisfacts/001/2017-12-07 documents: 7288it [00:00, 17445.87it/s]\n",
      "Java started (triggered by TerrierIndexer.__init__) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.10 (build: craigm 2024-08-22 17:33), helper_version=0.0.8]\n",
      "crisisfacts/001/2017-12-07 documents: 7288it [00:03, 2231.14it/s]\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:31:58.029 [main] WARN org.terrier.querying.ApplyTermPipeline -- The index has no termpipelines configuration, and no control configuration is found. Defaulting to global termpipelines configuration of 'Stopwords,PorterStemmer'. Set a termpipelines control to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "mine = crisis(events = eventsMeta)\n",
    "\n",
    "final_df, time_taken, memory_used = mine.rank_rerank_T5(model = 'BM25')\n",
    "result_df = mine.group_doc(final_df)\n",
    "a, b, c = mine.gpt_summary(result_df, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5800",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
