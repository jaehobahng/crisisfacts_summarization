{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09f20ad4-8290-439c-bfe5-4e78d12db873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee23c765-e851-4d65-9689-d57199ca6a99",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './result_df_before_summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./result_df_before_summary.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './result_df_before_summary.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./result_df_before_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "add16f4c-d007-4fb8-b9c9-a0e86c0f1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['unix_timestamp'], unit='s').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f412d8d-8b69-427f-90bf-d7d1cfe3ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df[[\"request_id\",\"query\",\"question\",\"date\",\"texts\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c3961a0-cfdb-4f18-bd7e-7f7d046c2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dff[dff['request_id'].str.startswith(\"CrisisFACTS-001-\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ba60ae3-7fd8-48ed-8083-cf1e7ee30d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So long everyone   @ Tijuana International Airport  Enmascarado.  . . . . .       I\\'m at San Diego International Airport -  in San Diego, CA  I\\'m at San Diego International Airport -  in San Diego, CA  La Jolla, CA Via La Jolla Light Newspaper \"As planes flying to and from San Diego Airport were rerouted to accommodate high winds on Dec. 7, the San Diego Regional Airport Authority met and voted to i'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = df1[\"texts\"][0]\n",
    "cleaned_txt = re.sub(r'#\\S+|https?://\\S+|@\\S+', '', txt)\n",
    "cleaned_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38861443-f992-4442-b069-bfb8c3427088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "parser = PlaintextParser.from_string(cleaned_txt, Tokenizer(\"english\"))\n",
    "summarizer = LsaSummarizer()\n",
    "summary = summarizer(parser.document, 1)  # 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b65cae77-4f70-4051-ab17-055d8fdf872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Sentence: I'm at San Diego International Airport -  in San Diego, CA  I'm at San Diego International Airport -  in San Diego, CA  La Jolla, CA Via La Jolla Light Newspaper \"As planes flying to and from San Diego Airport were rerouted to accommodate high winds on Dec. 7, the San Diego Regional Airport Authority met and voted to i>,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f6f88cc-2f7e-4464-9430-cf6575ca165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "bart_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-xsum\")\n",
    "pega_summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\")\n",
    "summary1 = bart_summarizer(cleaned_txt, max_length=52, min_length=30)\n",
    "summary2 = pega_summarizer(cleaned_txt, max_length=52, min_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8bcf0cb-d2c7-4a6e-be27-41cb3b1483d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An airport in Tijuana, Mexico, has reopened after being closed for more than 24 hours due to high winds on Christmas Eve and Christmas Day.\n",
      "High winds have forced the closure of San Diego's international airport for the second time in a week, with flights diverted to Tijuana, Mexico.\n"
     ]
    }
   ],
   "source": [
    "print(summary1[0]['summary_text'])\n",
    "print(summary2[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c969403-9685-4f45-92c0-b03d100e63f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 52, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 52, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 52, but your input_length is only 44. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 52, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "Your max_length is set to 52, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 52, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 52, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 52, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "Your max_length is set to 52, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 52, but your input_length is only 43. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n",
      "Your max_length is set to 52, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 52, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 52, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 52, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 52, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 52, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n",
      "Your max_length is set to 52, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent: 42 minutes and 40 seconds\n",
      "Memory used: 0.25 MB\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def clean_and_summarize(text, summarizer):\n",
    "    cleaned_txt = re.sub(r'#\\S+|https?://\\S+|@\\S+', '', text)\n",
    "    summary = summarizer(cleaned_txt, max_length=52, min_length=30)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "\n",
    "process = psutil.Process(os.getpid())\n",
    "initial_memory = process.memory_info().rss / (1024 * 1024)\n",
    "start_time = time.time()\n",
    "\n",
    "tqdm.pandas(desc=\"Processing texts\")\n",
    "# df1['summary'] = df1['texts'].apply(clean_and_summarize)\n",
    "df1['bart_summary'] = df1['texts'].apply(lambda x: clean_and_summarize(x, bart_summarizer))\n",
    "\n",
    "end_time = time.time()\n",
    "final_memory = process.memory_info().rss / (1024 * 1024)\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "memory_used = final_memory - initial_memory \n",
    "\n",
    "minutes = int(elapsed_time // 60) \n",
    "seconds = int(elapsed_time % 60)\n",
    "\n",
    "print(f\"Time spent: {minutes} minutes and {seconds} seconds\")\n",
    "print(f\"Memory used: {memory_used:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42fea5b5-ba79-48c9-a13b-6a1708bd0e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_id</th>\n",
       "      <th>query</th>\n",
       "      <th>question</th>\n",
       "      <th>date</th>\n",
       "      <th>texts</th>\n",
       "      <th>bart_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CrisisFACTS-001-r10</td>\n",
       "      <td>airport closed</td>\n",
       "      <td>Have airports closed</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>So long everyone   @ Tijuana International Air...</td>\n",
       "      <td>An airport in Tijuana, Mexico, has reopened af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CrisisFACTS-001-r10</td>\n",
       "      <td>rail closed</td>\n",
       "      <td>Have railways closed</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>The American Red Cross of San Diego/Imperial C...</td>\n",
       "      <td>The Camp Fire in San Diego has been fully cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CrisisFACTS-001-r10</td>\n",
       "      <td>water supply</td>\n",
       "      <td>Have water supplied been contaminated</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>A UH-1Y Venom refills its bucket firefighting ...</td>\n",
       "      <td>Firefighters in California have been using wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CrisisFACTS-001-r10</td>\n",
       "      <td>firefighters on-duty</td>\n",
       "      <td>How many firefighters are active</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>All 17 of the firefighters on the strike team ...</td>\n",
       "      <td>One of the firefighters killed in the Camp fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CrisisFACTS-001-r10</td>\n",
       "      <td>evacuated</td>\n",
       "      <td>How many people are affected</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>We evacuated last Thursday, around 1pm before ...</td>\n",
       "      <td>My wife and I were forced to evacuate our home...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>CrisisFACTS-001-r9</td>\n",
       "      <td>wind speed</td>\n",
       "      <td>Where are wind speeds expected to be high</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>Northeast winds are expected to reach speeds o...</td>\n",
       "      <td>The National Weather Service has issued a yell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>CrisisFACTS-001-r9</td>\n",
       "      <td>helicopters</td>\n",
       "      <td>Are helicopters available</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>The #SanDiego City Council has unanimously vot...</td>\n",
       "      <td>Firefighters in Los Angeles will soon be able ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>CrisisFACTS-001-r9</td>\n",
       "      <td>homes destroyed damaged</td>\n",
       "      <td>Where have homes been damaged or destroyed</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>So far, 701 homes, two apartment complexes and...</td>\n",
       "      <td>The number of homes destroyed by wildfires in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>CrisisFACTS-001-r9</td>\n",
       "      <td>acres per hour</td>\n",
       "      <td>How quickly is the fire spreading</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>Cal Fire reports that CALFIRE &amp; the US Forest ...</td>\n",
       "      <td>The number of wildfires burning in the US stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>CrisisFACTS-001-r9</td>\n",
       "      <td>containment</td>\n",
       "      <td>What is the fire containment level</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>Containment now at 95% for #LilacFire. @10News...</td>\n",
       "      <td>There has been a slight increase in the number...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>434 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              request_id                    query  \\\n",
       "0    CrisisFACTS-001-r10           airport closed   \n",
       "1    CrisisFACTS-001-r10              rail closed   \n",
       "2    CrisisFACTS-001-r10             water supply   \n",
       "3    CrisisFACTS-001-r10     firefighters on-duty   \n",
       "4    CrisisFACTS-001-r10                evacuated   \n",
       "..                   ...                      ...   \n",
       "429   CrisisFACTS-001-r9               wind speed   \n",
       "430   CrisisFACTS-001-r9              helicopters   \n",
       "431   CrisisFACTS-001-r9  homes destroyed damaged   \n",
       "432   CrisisFACTS-001-r9           acres per hour   \n",
       "433   CrisisFACTS-001-r9              containment   \n",
       "\n",
       "                                       question        date  \\\n",
       "0                          Have airports closed  2017-12-14   \n",
       "1                          Have railways closed  2017-12-14   \n",
       "2         Have water supplied been contaminated  2017-12-14   \n",
       "3              How many firefighters are active  2017-12-14   \n",
       "4                  How many people are affected  2017-12-14   \n",
       "..                                          ...         ...   \n",
       "429   Where are wind speeds expected to be high  2017-12-13   \n",
       "430                   Are helicopters available  2017-12-13   \n",
       "431  Where have homes been damaged or destroyed  2017-12-13   \n",
       "432           How quickly is the fire spreading  2017-12-13   \n",
       "433          What is the fire containment level  2017-12-13   \n",
       "\n",
       "                                                 texts  \\\n",
       "0    So long everyone   @ Tijuana International Air...   \n",
       "1    The American Red Cross of San Diego/Imperial C...   \n",
       "2    A UH-1Y Venom refills its bucket firefighting ...   \n",
       "3    All 17 of the firefighters on the strike team ...   \n",
       "4    We evacuated last Thursday, around 1pm before ...   \n",
       "..                                                 ...   \n",
       "429  Northeast winds are expected to reach speeds o...   \n",
       "430  The #SanDiego City Council has unanimously vot...   \n",
       "431  So far, 701 homes, two apartment complexes and...   \n",
       "432  Cal Fire reports that CALFIRE & the US Forest ...   \n",
       "433  Containment now at 95% for #LilacFire. @10News...   \n",
       "\n",
       "                                          bart_summary  \n",
       "0    An airport in Tijuana, Mexico, has reopened af...  \n",
       "1    The Camp Fire in San Diego has been fully cont...  \n",
       "2    Firefighters in California have been using wat...  \n",
       "3    One of the firefighters killed in the Camp fir...  \n",
       "4    My wife and I were forced to evacuate our home...  \n",
       "..                                                 ...  \n",
       "429  The National Weather Service has issued a yell...  \n",
       "430  Firefighters in Los Angeles will soon be able ...  \n",
       "431  The number of homes destroyed by wildfires in ...  \n",
       "432  The number of wildfires burning in the US stat...  \n",
       "433  There has been a slight increase in the number...  \n",
       "\n",
       "[434 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1afbaa6-2b23-4c0c-a3c8-5bba4f4b6e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
