{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed85e9d8-1155-4b51-8e38-b625381751fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0c17a4-1c29-44d2-97fb-5b9e50a0e862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"result_df_before_summary.csv\")\n",
    "df['date'] = pd.to_datetime(df['unix_timestamp'], unit='s').dt.date\n",
    "dff = df[[\"request_id\",\"query\",\"question\",\"date\",\"texts\"]]\n",
    "df1 = dff[dff['request_id'].str.startswith(\"CrisisFACTS-001-\")]\n",
    "\n",
    "bart_summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-xsum\")\n",
    "pega_summarizer = pipeline(\"summarization\", model=\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c23b1fde-7564-4f56-9415-9fb5f3fcf0b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 52, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 52, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 52, but your input_length is only 44. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=22)\n",
      "Your max_length is set to 52, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 52, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 52, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 52, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "/opt/conda/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Your max_length is set to 52, but your input_length is only 48. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n",
      "Your max_length is set to 52, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
      "Your max_length is set to 52, but your input_length is only 43. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n",
      "Your max_length is set to 52, but your input_length is only 47. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=23)\n",
      "Your max_length is set to 52, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 52, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n",
      "Your max_length is set to 52, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n",
      "Your max_length is set to 52, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
      "Your max_length is set to 52, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n",
      "Your max_length is set to 52, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n",
      "Your max_length is set to 52, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n",
      "Your max_length is set to 52, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n",
      "/tmp/ipykernel_5990/3891853409.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['bart_summary'] = [summary for batch_result in results for summary in batch_result]\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "num_batches = num_cores * 2\n",
    "\n",
    "# Split the dataset into batches\n",
    "batches = np.array_split(df1['texts'], num_batches)\n",
    "\n",
    "def clean_and_summarize(text, summarizer):\n",
    "    cleaned_txt = re.sub(r'#\\S+|https?://\\S+|@\\S+', '', text)\n",
    "    summary = summarizer(cleaned_txt, max_length=52, min_length=30)\n",
    "    return summary[0]['summary_text']\n",
    "    \n",
    "def clean_and_summarize_parallel(texts):\n",
    "    return [clean_and_summarize(text, bart_summarizer) for text in texts]\n",
    "    \n",
    "# Apply parallel processing\n",
    "results = Parallel(n_jobs=num_cores)(\n",
    "    delayed(clean_and_summarize_parallel)(batch.tolist()) for batch in batches\n",
    ")\n",
    "\n",
    "# Combine results back into the DataFrame\n",
    "df1['bart_summary'] = [summary for batch_result in results for summary in batch_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b773515-1ca5-477b-84f6-3db91d530b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"summary\"] = df1[\"bart_summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f0be69b-b001-4601-8b3d-5dcb80c0cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_submission_bart_detail.json\", 'w') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        fact_ = {\n",
    "            \"requestID\": row['request_id'],\n",
    "            \"factText\": row['summary'],\n",
    "            \"unixTimestamp\": int(row['unix_timestamp']),\n",
    "            \"importance\": float(row['avg_importance']),\n",
    "            \"sources\": row['docno_list'],\n",
    "            \"streamID\": None,\n",
    "            \"informationNeeds\": row['q_id']\n",
    "        }\n",
    "        \n",
    "        # Write each dictionary as a separate JSON object on a new line\n",
    "        json.dump(fact_, f)\n",
    "        f.write(\"\\n\")  # Add a newline after each JSON object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9383614b-b874-446f-b7e6-67464f8a60f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('bart.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c70a22ef-bdae-40bb-b512-2933f2b3237f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './submission_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Loop through all files in the input folder\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     10\u001b[0m     input_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, file_name)\n\u001b[1;32m     11\u001b[0m     output_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './submission_json'"
     ]
    }
   ],
   "source": [
    "# Define the input and output folder paths\n",
    "input_folder = \"./submission_json\"\n",
    "output_folder = \"./submissions\"\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    input_file_path = os.path.join(input_folder, file_name)\n",
    "    output_file_path = os.path.join(output_folder, f\"{file_name}.gz\")\n",
    "\n",
    "    # Check if the current item is a file (not a folder)\n",
    "    if os.path.isfile(input_file_path):\n",
    "        # Open the input file and compress it into the output folder\n",
    "        with open(input_file_path, \"rb\") as f_in:\n",
    "            with gzip.open(output_file_path, \"wb\") as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        print(f\"Compressed: {input_file_path} -> {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489b9c8-04f2-4104-af8e-35efa815903c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
