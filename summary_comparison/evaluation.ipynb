{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b9a29fa-53e3-4e8b-9806-73c6c689beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import shutil\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import gzip\n",
    "import bert_score\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "import glob\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ba5715b-e458-4cbc-8f58-1159a6bcbe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_summary(url):\n",
    "    \n",
    "    if \"wikipedia.org\" not in url:\n",
    "        return \"\"\n",
    "    \n",
    "    page_title = url.rpartition(\"/\")[-1]\n",
    "    page = wikipedia.page(title=page_title, auto_suggest=False)\n",
    "    \n",
    "    return page.summary\n",
    "    \n",
    "event_df = pd.read_json(\"CrisisFACTs-2022to2023.topics.json\", lines=False).set_index(\"eventID\")\n",
    "event_df[\"wiki.summary\"] = event_df[\"url\"].apply(get_wiki_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79741d37-3b20-47a1-aa5b-9f79205d1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final-annotated-facts-results.json\", \"r\") as in_file:\n",
    "    annotation_data = json.load(in_file)\n",
    "\n",
    "all_req_ids = list(annotation_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b52f931-d13f-458e-8394-4da3255577ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = ROUGEScore(\n",
    "    use_stemmer=True,\n",
    "    rouge_keys=(\"rouge2\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d75d76f8-a3c0-4b24-92c3-8b09ab9813f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submissions/my_submission_pega_detail.json.gz --> my_submission_pega_detail.json\n",
      "CrisisFACTS-001 48424\n",
      "Bert Score\n",
      "      metric     value            event\n",
      "0  precision  0.717838  CrisisFACTS-001\n",
      "1     recall  0.743328  CrisisFACTS-001\n",
      "2         f1  0.730361  CrisisFACTS-001\n",
      "-------------------------------\n",
      "Rouge Score\n",
      "      metric     value            event\n",
      "0  precision  0.004859  CrisisFACTS-001\n",
      "1     recall  0.291667  CrisisFACTS-001\n",
      "2         f1  0.009558  CrisisFACTS-001\n",
      "\n",
      "\n",
      "submissions/my_submission_gpt_detail.json.gz --> my_submission_gpt_detail.json\n",
      "CrisisFACTS-001 10049\n",
      "Bert Score\n",
      "      metric     value            event\n",
      "0  precision  0.695280  CrisisFACTS-001\n",
      "1     recall  0.727899  CrisisFACTS-001\n",
      "2         f1  0.711216  CrisisFACTS-001\n",
      "-------------------------------\n",
      "Rouge Score\n",
      "      metric     value            event\n",
      "0  precision  0.014393  CrisisFACTS-001\n",
      "1     recall  0.145833  CrisisFACTS-001\n",
      "2         f1  0.026201  CrisisFACTS-001\n",
      "\n",
      "\n",
      "submissions/my_submission_bart_detail.json.gz --> my_submission_bart_detail.json\n",
      "CrisisFACTS-001 42618\n",
      "Bert Score\n",
      "      metric     value            event\n",
      "0  precision  0.720050  CrisisFACTS-001\n",
      "1     recall  0.745512  CrisisFACTS-001\n",
      "2         f1  0.732560  CrisisFACTS-001\n",
      "-------------------------------\n",
      "Rouge Score\n",
      "      metric     value            event\n",
      "0  precision  0.005953  CrisisFACTS-001\n",
      "1     recall  0.319444  CrisisFACTS-001\n",
      "2         f1  0.011688  CrisisFACTS-001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_K = 32\n",
    "\n",
    "for f in glob.glob(\"submissions/*.gz\"):\n",
    "    this_run_id = f.partition(\"/\")[-1].replace(\".gz\", \"\")\n",
    "    print(f, \"-->\", this_run_id)\n",
    "    \n",
    "    # Reset the summary for the current file\n",
    "    local_event_summaries = {\"CrisisFACTS-001\": []}\n",
    "\n",
    "    this_run_event_request_facts = {k: [] for k in all_req_ids}\n",
    "    \n",
    "    # Read and process the gzip file\n",
    "    with gzip.open(f, \"r\") as in_file:\n",
    "        for line_ in in_file:\n",
    "            line = line_.decode(\"utf8\")\n",
    "            entry = json.loads(line)\n",
    "            this_req_id = entry[\"requestID\"]\n",
    "            \n",
    "            # Skip requests with no relevant facts\n",
    "            if this_req_id not in all_req_ids:\n",
    "                continue\n",
    "            \n",
    "            this_run_event_request_facts[this_req_id].append(entry)\n",
    "    \n",
    "    # Process facts only for 'CrisisFACTS-001'\n",
    "    for event_request, this_fact_list in this_run_event_request_facts.items():\n",
    "        event_id = event_request.rpartition(\"-\")[0]\n",
    "\n",
    "        if event_id != 'CrisisFACTS-001':\n",
    "            continue\n",
    "\n",
    "        sorted_fact_list = sorted(this_fact_list, key=lambda v: v[\"importance\"], reverse=True)\n",
    "        this_day_summary = [this_top_fact[\"factText\"] for this_top_fact in sorted_fact_list[:TOP_K]]\n",
    "        \n",
    "        local_event_summaries[\"CrisisFACTS-001\"] += this_day_summary\n",
    "        \n",
    "    # Compute metrics only for 'CrisisFACTS-001'\n",
    "    event_id = \"CrisisFACTS-001\"\n",
    "    this_submitted_summary = local_event_summaries[event_id]\n",
    "\n",
    "    try:\n",
    "        this_summary_text = \". \".join(this_submitted_summary).replace(\"..\", \".\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing summary for {event_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    print(event_id, len(this_summary_text))\n",
    "    \n",
    "    # Retrieve the corresponding wiki summary\n",
    "    wiki_summary = event_df.loc[event_id, \"wiki.summary\"]\n",
    "    \n",
    "    wiki_metric_bert_ = bert_score.score([this_summary_text], [wiki_summary], model_type=\"roberta-large-mnli\")\n",
    "    wiki_metric_rouge_ = rouge(this_summary_text, wiki_summary)\n",
    "    \n",
    "    wiki_metric_bert = {\n",
    "        \"precision\": wiki_metric_bert_[0],\n",
    "        \"recall\": wiki_metric_bert_[1],\n",
    "        \"f1\": wiki_metric_bert_[2],\n",
    "    }\n",
    "\n",
    "    wiki_metric_rouge = {\n",
    "        \"precision\": wiki_metric_rouge_[\"rouge2_precision\"],\n",
    "        \"recall\": wiki_metric_rouge_[\"rouge2_recall\"],\n",
    "        \"f1\": wiki_metric_rouge_[\"rouge2_fmeasure\"],\n",
    "    }\n",
    "    \n",
    "\n",
    "    this_wiki_df_bert = pd.DataFrame([{\"metric\": k, \"value\": v.item(), \"event\": event_id} for k, v in wiki_metric_bert.items()])\n",
    "    this_wiki_df_rouge = pd.DataFrame([{\"metric\": k, \"value\": v.item(), \"event\": event_id} for k, v in wiki_metric_rouge.items()])\n",
    "\n",
    "    print(\"Bert Score\")\n",
    "    print(this_wiki_df_bert)\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Rouge Score\")\n",
    "    print(this_wiki_df_rouge)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fdf1f2-a977-44fb-bee3-ce3bf2d501c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
