{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9a29fa-53e3-4e8b-9806-73c6c689beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import psutil\n",
    "import shutil\n",
    "import os\n",
    "from transformers import pipeline\n",
    "import json\n",
    "import gzip\n",
    "import bert_score\n",
    "import glob\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba5715b-e458-4cbc-8f58-1159a6bcbe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Lilac_Fire\n",
      "https://en.wikipedia.org/wiki/Cranston_Fire\n",
      "https://en.wikipedia.org/wiki/Holy_Fire_(2018)\n",
      "https://en.wikipedia.org/wiki/Hurricane_Florence\n",
      "https://en.wikipedia.org/wiki/2018_Maryland_flood\n",
      "https://en.wikipedia.org/wiki/Saddleridge_Fire\n",
      "https://en.wikipedia.org/wiki/Hurricane_Laura\n",
      "https://en.wikipedia.org/wiki/Hurricane_Sally\n",
      "https://en.wikipedia.org/wiki/2020_Beirut_explosion\n",
      "https://en.wikipedia.org/wiki/2020_Houston_explosion\n",
      "https://en.wikipedia.org/wiki/Edenville_Dam#Dam_failure\n",
      "https://en.wikipedia.org/wiki/Hurricane_Dorian\n",
      "https://en.wikipedia.org/wiki/Kincade_Fire\n",
      "https://en.wikipedia.org/wiki/2020_Easter_tornado_outbreak\n",
      "https://en.wikipedia.org/wiki/Tornado_outbreak_of_April_22-23,_2020\n",
      "https://en.wikipedia.org/wiki/Tornado_outbreak_of_March_2-3,_2020\n"
     ]
    }
   ],
   "source": [
    "def get_wiki_summary(url):\n",
    "    \n",
    "    if \"wikipedia.org\" not in url:\n",
    "        return \"\"\n",
    "    \n",
    "    page_title = url.rpartition(\"/\")[-1]\n",
    "    print(url)\n",
    "    page = wikipedia.page(title=page_title, auto_suggest=False)\n",
    "    \n",
    "    return page.summary\n",
    "    \n",
    "event_df = pd.read_json(\"CrisisFACTs-2022to2023.topics.json\", lines=False).set_index(\"eventID\")\n",
    "event_df[\"wiki.summary\"] = event_df[\"url\"].apply(get_wiki_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79741d37-3b20-47a1-aa5b-9f79205d1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final-annotated-facts-results.json\", \"r\") as in_file:\n",
    "    annotation_data = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d75d76f8-a3c0-4b24-92c3-8b09ab9813f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submissions/my_submission_pega_detail.json.gz --> my_submission_pega_detail.json\n",
      "CrisisFACTS-001 48424\n",
      "      metric     value            event\n",
      "0  precision  0.717838  CrisisFACTS-001\n",
      "1     recall  0.743328  CrisisFACTS-001\n",
      "2         f1  0.730361  CrisisFACTS-001\n",
      "submissions/my_submission_bart_detail.json.gz --> my_submission_bart_detail.json\n",
      "CrisisFACTS-001 42618\n",
      "      metric     value            event\n",
      "0  precision  0.720050  CrisisFACTS-001\n",
      "1     recall  0.745512  CrisisFACTS-001\n",
      "2         f1  0.732560  CrisisFACTS-001\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob(\"submissions/*.gz\"):\n",
    "    this_run_id = f.partition(\"/\")[-1].replace(\".gz\", \"\")\n",
    "    print(f, \"-->\", this_run_id)\n",
    "    \n",
    "    # Reset the summary for the current file\n",
    "    local_event_summaries = {\"CrisisFACTS-001\": []}\n",
    "\n",
    "    this_run_event_request_facts = {k: [] for k in all_req_ids}\n",
    "    \n",
    "    # Read and process the gzip file\n",
    "    with gzip.open(f, \"r\") as in_file:\n",
    "        for line_ in in_file:\n",
    "            line = line_.decode(\"utf8\")\n",
    "            entry = json.loads(line)\n",
    "            this_req_id = entry[\"requestID\"]\n",
    "            \n",
    "            # Skip requests with no relevant facts\n",
    "            if this_req_id not in all_req_ids:\n",
    "                continue\n",
    "            \n",
    "            this_run_event_request_facts[this_req_id].append(entry)\n",
    "    \n",
    "    # Process facts only for 'CrisisFACTS-001'\n",
    "    for event_request, this_fact_list in this_run_event_request_facts.items():\n",
    "        event_id = event_request.rpartition(\"-\")[0]\n",
    "\n",
    "        if event_id != 'CrisisFACTS-001':\n",
    "            continue\n",
    "\n",
    "        sorted_fact_list = sorted(this_fact_list, key=lambda v: v[\"importance\"], reverse=True)\n",
    "        this_day_summary = [this_top_fact[\"factText\"] for this_top_fact in sorted_fact_list[:TOP_K]]\n",
    "        \n",
    "        local_event_summaries[\"CrisisFACTS-001\"] += this_day_summary\n",
    "        \n",
    "    # Compute metrics only for 'CrisisFACTS-001'\n",
    "    event_id = \"CrisisFACTS-001\"\n",
    "    this_submitted_summary = local_event_summaries[event_id]\n",
    "\n",
    "    try:\n",
    "        this_summary_text = \". \".join(this_submitted_summary).replace(\"..\", \".\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing summary for {event_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "    print(event_id, len(this_summary_text))\n",
    "    \n",
    "    # Retrieve the corresponding wiki summary\n",
    "    wiki_summary = event_df.loc[event_id, \"wiki.summary\"]\n",
    "    wiki_metric_ = bert_score.score([this_summary_text], [wiki_summary], model_type=\"roberta-large-mnli\")\n",
    "\n",
    "    wiki_metric = {\n",
    "        \"precision\": wiki_metric_[0],\n",
    "        \"recall\": wiki_metric_[1],\n",
    "        \"f1\": wiki_metric_[2],\n",
    "    }\n",
    "\n",
    "    this_wiki_df = pd.DataFrame([{\"metric\": k, \"value\": v.item(), \"event\": event_id} for k, v in wiki_metric.items()])\n",
    "    print(this_wiki_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
