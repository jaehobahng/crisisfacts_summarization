{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event numbers as a list\n",
    "eventNoList = [\n",
    "    \"001\", # Lilac Wildfire 2017\n",
    "    \"002\", # Cranston Wildfire 2018\n",
    "    \"003\", # Holy Wildfire 2018\n",
    "    \"004\", # Hurricane Florence 2018\n",
    "    \"005\", # 2018 Maryland Flood\n",
    "    \"006\", # Saddleridge Wildfire 2019\n",
    "    \"007\", # Hurricane Laura 2020\n",
    "    \"008\", # Hurricane Sally 2020\n",
    "    \"009\", # Beirut Explosion, 2020\n",
    "    \"010\", # Houston Explosion, 2020\n",
    "    \"011\", # Rutherford TN Floods, 2020\n",
    "    \"012\", # TN Derecho, 2020\n",
    "    \"013\", # Edenville Dam Fail, 2020\n",
    "    \"014\", # Hurricane Dorian, 2019\n",
    "    \"015\", # Kincade Wildfire, 2019\n",
    "    \"016\", # Easter Tornado Outbreak, 2020\n",
    "    \"017\", # Tornado Outbreak, 2020 Apr\n",
    "    \"018\", # Tornado Outbreak, 2020 March\n",
    "]\n",
    "\n",
    "\n",
    "eventNoList = [\n",
    "    \"001\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_input = '001,002'\n",
    "eventNoList = event_input.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ir_datasets\n",
    "import pandas as pd\n",
    "\n",
    "# Gets the list of days for a specified event number, e.g. '001'\n",
    "def getDaysForEventNo(eventNo):\n",
    "\n",
    "    # We will download a file containing the day list for an event\n",
    "    url = \"http://trecis.org/CrisisFACTs/CrisisFACTS-\"+eventNo+\".requests.json\"\n",
    "\n",
    "    # Download the list and parse as JSON\n",
    "    dayList = requests.get(url).json()\n",
    "\n",
    "    return dayList\n",
    "\n",
    "def get_eventsMeta(eventNoList, days):\n",
    "\n",
    "    eventsMeta = {}\n",
    "\n",
    "    for eventNo in eventNoList: # for each event\n",
    "        \n",
    "        dailyInfo = getDaysForEventNo(eventNo) # get the list of days\n",
    "        eventsMeta[eventNo]= dailyInfo[:days]\n",
    "    \n",
    "    \n",
    "        \n",
    "        # print(\"Event \"+eventNo)\n",
    "        # for day in dailyInfo: # for each day\n",
    "        #     print(\"  crisisfacts/\"+eventNo+\"/\"+day[\"dateString\"], \"-->\", day[\"requestID\"]) # construct the request string\n",
    "\n",
    "        # print()\n",
    "    return eventsMeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsMeta = get_eventsMeta(eventNoList, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"institution\": \"Georgetown University\", # University, Company or Public Agency Name\n",
    "    \"contactname\": \"JaeHo Bahng\", # Your Name\n",
    "    \"email\": \"jaheo127@gmail.com\", # A contact email address\n",
    "    \"institutiontype\": \"Academic\" # Either 'Research', 'Industry', or 'Public Sector'\n",
    "}\n",
    "\n",
    "# Write this to a file so it can be read when needed\n",
    "import json\n",
    "\n",
    "with open('../../auth/crisisfacts.json', 'w') as f:\n",
    "    json.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "# from pyterrier_t5 import MonoT5ReRanker, DuoT5ReRanker\n",
    "import os\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import time\n",
    "from rerankers import Reranker\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# Load variables from the .env file\n",
    "load_dotenv('../../.env')\n",
    "api = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "models = [\n",
    "    \"BM25\",          # Okapi BM25\n",
    "    \"TF_IDF\",        # Term Frequency - Inverse Document Frequency\n",
    "    \"PL2\",           # Divergence from Randomness model\n",
    "    \"InL2\",          # Inverse document length normalized\n",
    "    \"DPH\",           # Divergence from Randomness - DPH\n",
    "    \"DirichletLM\",   # Language Model with Dirichlet smoothing\n",
    "    \"Hiemstra_LM\",   # Hiemstra Language Model\n",
    "    \"DFRee\",         # Divergence-Free model\n",
    "]\n",
    "\n",
    "os.environ[\"PT_NO_PROGRESS\"] = \"1\"\n",
    "os.environ['IR_DATASETS_HOME'] = '../../'\n",
    "\n",
    "class crisis:\n",
    "    def __init__(self, events):\n",
    "        self.eventsMeta = events\n",
    "\n",
    "    def rank_rerank_colbert(self, model = 'BM25'):\n",
    "        process = psutil.Process(os.getpid())  # Get current process\n",
    "        start_memory = process.memory_info().rss  # Memory usage at start (in bytes)\n",
    "        start_time = time.time()  # Start time\n",
    "\n",
    "        final_df = pd.DataFrame()\n",
    "        ranker = Reranker(\"answerdotai/answerai-colbert-small-v1\", model_type='colbert')\n",
    "\n",
    "        for eventId, dailyInfo in self.eventsMeta.items():\n",
    "            for thisDay in dailyInfo:\n",
    "                try:\n",
    "                    ir_dataset_id = \"crisisfacts/%s/%s\" % (eventId, thisDay[\"dateString\"])\n",
    "                    print(ir_dataset_id, \" processing\")  \n",
    "        \n",
    "                    pyTerrierDataset = pt.get_dataset(f'irds:{ir_dataset_id}')\n",
    "                    queries = pyTerrierDataset.get_topics()\n",
    "                    dataset = pd.DataFrame(pyTerrierDataset.get_corpus_iter(), columns=['docno', 'text', 'unix_timestamp'])\n",
    "        \n",
    "                    indexer = pt.IterDictIndexer(\"None\", type=pt.index.IndexingType(3), meta=[\"docno\", \"text\"], meta_lengths=[0, 200])\n",
    "                    index = indexer.index(pyTerrierDataset.get_corpus_iter())\n",
    "                        \n",
    "                    retriever = pt.terrier.Retriever(index, wmodel=model, metadata=[\"docno\", \"text\"])\n",
    "                    retriever.setControl(\"termpipelines\", \"Stopwords,PorterStemmer\")\n",
    "        \n",
    "                    for _, row in queries.iterrows():\n",
    "                        # matching_index = int(queries[queries['indicative_terms'] == row['indicative_terms']].index[0])\n",
    "                        # print(ir_dataset_id, \"query num : \", matching_index)\n",
    "\n",
    "                        retriever_df = pd.DataFrame(retriever.search(row['indicative_terms']))\n",
    "                        retriever_df = retriever_df[~retriever_df['text'].isnull()]\n",
    "                        retriever_df = retriever_df[retriever_df['rank']<50]\n",
    "                        retriever_df['docid'] = retriever_df['docid'].astype(int)\n",
    "        \n",
    "        \n",
    "                        retriever_df['Event'] = eventId\n",
    "                        retriever_df['request_id'] = thisDay['requestID']\n",
    "                        retriever_df['date'] = thisDay['dateString']\n",
    "                        retriever_df['q_id'] = row['qid']\n",
    "                        retriever_df['question'] = row['text']\n",
    "        \n",
    "        \n",
    "                        if not retriever_df.empty:\n",
    "                            # Rerank\n",
    "                            result = ranker.rank(query=row['indicative_terms'], docs=retriever_df['text'], doc_ids=retriever_df['docid'])\n",
    "                            \n",
    "                            rereank_score = [i.score for i in result.results]\n",
    "                            rerank_rank = [i.rank for i in result.results]\n",
    "                            rerank_doc = [i.doc_id for i in result.results]\n",
    "        \n",
    "                            # Creating a DataFrame\n",
    "                            df = pd.DataFrame({\n",
    "                                'rerank_score': rereank_score,\n",
    "                                'rerank_rank': rerank_rank,\n",
    "                                'rerank_doc': rerank_doc\n",
    "                            })\n",
    "        \n",
    "                            retriever_df = retriever_df.merge(df, left_on='docid', right_on='rerank_doc', how='left')\n",
    "        \n",
    "                            retriever_df = retriever_df[retriever_df['rerank_rank']<=5]\n",
    "        \n",
    "                            #Clean\n",
    "                            result_df = retriever_df.sort_values('rerank_rank', ascending=True).reset_index(drop=True)\n",
    "                            result_df = result_df.merge(dataset[['docno', 'unix_timestamp']], on='docno', how='left')\n",
    "        \n",
    "                            # Append to final_df\n",
    "                            final_df = pd.concat([final_df, result_df], ignore_index=True)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "        final_df['formatted_datetime'] = pd.to_datetime(final_df['unix_timestamp'], unit='s')\n",
    "\n",
    "        min_max = (\n",
    "            final_df.groupby(['request_id'])\n",
    "            .agg(\n",
    "                min=('rerank_score','min'),\n",
    "                max=('rerank_score', 'max')\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        final_df = final_df.merge(min_max, on='request_id', how='left')\n",
    "        final_df['importance'] = (final_df['rerank_score'] - final_df['min']) / (final_df['max'] - final_df['min'])\n",
    "\n",
    "        # Calculate runtime and memory usage\n",
    "        end_time = time.time()  # End time\n",
    "        end_memory = process.memory_info().rss  # Memory usage at end (in bytes)\n",
    "        runtime = end_time - start_time\n",
    "        memory_used = (end_memory - start_memory) / 1024 / 1024  # Convert bytes to MB\n",
    "\n",
    "        return final_df, runtime, memory_used\n",
    "\n",
    "\n",
    "    def group_doc(self, df):\n",
    "        result_df = (\n",
    "            df.groupby(['request_id', 'q_id'])\n",
    "            .agg(\n",
    "                texts=('text', ' '.join),                     # Join all text values into a single string\n",
    "                docno_list=('docno', list),                   # Collect docno values in a list\n",
    "                avg_importance=('importance', 'mean'),        # Calculate the average importance\n",
    "                unix_timestamp =('unix_timestamp', 'min'),\n",
    "                question = ('question', 'min'),\n",
    "                query = ('query','min')\n",
    "            )\n",
    "            .reset_index()                                    # Reset index for a clean DataFrame\n",
    "        )\n",
    "        return result_df\n",
    "\n",
    "\n",
    "    def gpt_summary(self, df, api):\n",
    "        # Set your OpenAI API key\n",
    "        openai.api_key = api\n",
    "\n",
    "        process = psutil.Process(os.getpid())  # Get current process\n",
    "        start_memory = process.memory_info().rss  # Memory usage at start (in bytes)\n",
    "        start_time = time.time()  # Start time\n",
    "\n",
    "        answer_output = []\n",
    "        for i, row in df.iterrows():\n",
    "            question = str(row['question'] + \"?\")\n",
    "            provided_text = row['texts']\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            You are a helpful assistant. Answer the question based only on the text provided below. \n",
    "            If no answers can be found at all, return \"unanswerable\"\n",
    "\n",
    "            Don't make the responses conversational.\n",
    "            Expressions like hundreds of thousands can be answers to questions asking how many or how much.\n",
    "            Do not line break the text and just give me the output.\n",
    "\n",
    "            Text:\n",
    "            {provided_text}\n",
    "\n",
    "            Question:\n",
    "            {question}\n",
    "            \"\"\"\n",
    "\n",
    "            client = openai.OpenAI()\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=150\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            answer_output.append(answer)\n",
    "            # Print progress every 10 loops\n",
    "            # if (i + 1) % 50 == 0:\n",
    "            #     print(f\"Processed {i + 1} rows\")\n",
    "\n",
    "        df['summary'] = answer_output\n",
    "\n",
    "        end_time = time.time()  # End time\n",
    "        end_memory = process.memory_info().rss  # Memory usage at end (in bytes)\n",
    "\n",
    "        # Calculate metrics\n",
    "        runtime = end_time - start_time\n",
    "        memory_used = (end_memory - start_memory) / 1024 / 1024  # Convert bytes to MB\n",
    "\n",
    "        # Return results and performance metrics\n",
    "        return df, runtime, memory_used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ColBERTRanker model answerdotai/answerai-colbert-small-v1 (this message can be suppressed by setting verbose=0)\n",
      "No device set\n",
      "Using device cuda\n",
      "No dtype set\n",
      "Using dtype torch.float32\n",
      "Loading model answerdotai/answerai-colbert-small-v1, this might take a while...\n",
      "Linear Dim set to: 96 for downcasting\n",
      "crisisfacts/001/2017-12-07  processing\n",
      "There are multiple query fields available: ('text', 'indicative_terms', 'trecis_category_mapping', 'event_id', 'event_title', 'event_dataset', 'event_description', 'event_trecis_id', 'event_type', 'event_url'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crisisfacts/001/2017-12-07 documents: 7288it [00:00, 14802.68it/s]\n",
      "crisisfacts/001/2017-12-07 documents: 7288it [00:01, 4660.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crisisfacts/002/2018-07-25  processing\n",
      "There are multiple query fields available: ('text', 'indicative_terms', 'trecis_category_mapping', 'event_id', 'event_title', 'event_dataset', 'event_description', 'event_trecis_id', 'event_type', 'event_url'). To use with pyterrier, provide variant or modify dataframe to add query column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "crisisfacts/002/2018-07-25 documents: 5056it [00:00, 38269.86it/s]\n",
      "crisisfacts/002/2018-07-25 documents: 5056it [00:01, 4754.96it/s]\n"
     ]
    }
   ],
   "source": [
    "mine = crisis(events = eventsMeta)\n",
    "\n",
    "final_df, time_taken, memory_used = mine.rank_rerank_colbert(model = 'BM25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = mine.group_doc(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = mine.gpt_summary(result_df, api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crisis_summary.crisis_summary import crisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsan5800",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
